{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Wzu_rvVOvIft"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Configuration\n",
    "\n",
    "Configure which model formats to export. Multiple formats can be enabled simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXPORT CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "# Quantization Options\n",
    "EXPORT_INT8_FULL = False\n",
    "EXPORT_FP16 = False\n",
    "EXPORT_DYNAMIC = False\n",
    "EXPORT_INT8_PRUNED = True\n",
    "EXPORT_FP16_PRUNED = True\n",
    "\n",
    "# Edge TPU Compilation\n",
    "COMPILE_EDGE_TPU = True          # Compile INT8 models for Coral TPU\n",
    "\n",
    "# Pruning Configuration (if enabled)\n",
    "PRUNING_INITIAL_SPARSITY = 0.0   # Start with 0% sparsity\n",
    "PRUNING_FINAL_SPARSITY = 0.5     # End with 50% sparsity\n",
    "PRUNING_BEGIN_STEP = 0\n",
    "PRUNING_END_STEP = 1000\n",
    "PRUNING_FREQUENCY = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMJOOOb-vIfv"
   },
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "cJd8h9AuvIfw"
   },
   "outputs": [],
   "source": [
    "dataset = 'model/point_history_classifier/point_history.csv'\n",
    "model_save_path = 'model/point_history_classifier/point_history_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvOgeU9ivIfw"
   },
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "yym-K6cpvIfw"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYnBVymnvIfw"
   },
   "source": [
    "# 入力長"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "hvSD8ZomvIfx"
   },
   "outputs": [],
   "source": [
    "TIME_STEPS = 16\n",
    "DIMENSION = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6xy5JETvIfx"
   },
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "OE4mDI5avIfx"
   },
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (TIME_STEPS * DIMENSION) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "yR2EP-vevIfy"
   },
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "wyJf3nVTvIfy"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1ec59e7vIfy"
   },
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  Training with pruning enabled\n",
      "  Pruning: 0.0% → 50.0% sparsity\n"
     ]
    }
   ],
   "source": [
    "# Check if pruning is enabled\n",
    "USE_PRUNING = EXPORT_INT8_PRUNED or EXPORT_FP16_PRUNED\n",
    "use_lstm = False\n",
    "\n",
    "if USE_PRUNING:\n",
    "    print(\"⚙️  Training with pruning enabled\")\n",
    "    \n",
    "    # Build base model\n",
    "    if use_lstm:\n",
    "        base_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "            tf.keras.layers.Reshape((TIME_STEPS, DIMENSION), input_shape=(TIME_STEPS * DIMENSION, )), \n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.LSTM(16, time_major=False, return_sequences=True),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(10, activation='relu'),\n",
    "            tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "        ])\n",
    "    else:\n",
    "        base_model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(24, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(10, activation='relu'),\n",
    "            tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    # Apply pruning\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=PRUNING_INITIAL_SPARSITY,\n",
    "            final_sparsity=PRUNING_FINAL_SPARSITY,\n",
    "            begin_step=PRUNING_BEGIN_STEP,\n",
    "            end_step=PRUNING_END_STEP,\n",
    "            frequency=PRUNING_FREQUENCY\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    model = tfmot.sparsity.keras.prune_low_magnitude(base_model, **pruning_params)\n",
    "    print(f\"  Pruning: {PRUNING_INITIAL_SPARSITY*100}% → {PRUNING_FINAL_SPARSITY*100}% sparsity\")\n",
    "else:\n",
    "    print(\"⚙️  Training without pruning\")\n",
    "    if use_lstm:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "            tf.keras.layers.Reshape((TIME_STEPS, DIMENSION), input_shape=(TIME_STEPS * DIMENSION, )), \n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.LSTM(16, time_major=False, return_sequences=True),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(10, activation='relu'),\n",
    "            tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "        ])\n",
    "    else:\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Dense(24, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(10, activation='relu'),\n",
    "            tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldLE_fH0vIfz",
    "outputId": "da9b9b8e-a1e1-4b94-bdf8-6a2b63277b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_dropout  (None, 32)               1         \n",
      " _6 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_7  (None, 24)               1562      \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dropout  (None, 24)               1         \n",
      " _7 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_8  (None, 10)               492       \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_9  (None, 4)                86        \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,142\n",
      "Trainable params: 1,086\n",
      "Non-trainable params: 1,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added pruning callback\n"
     ]
    }
   ],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)\n",
    "\n",
    "# Add pruning callback if pruning is enabled\n",
    "callbacks_list = [cp_callback, es_callback]\n",
    "if USE_PRUNING:\n",
    "    import tensorflow_model_optimization as tfmot\n",
    "    pruning_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
    "    callbacks_list.append(pruning_callback)\n",
    "    print(\"Added pruning callback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "bqg4IRS_vIf0"
   },
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x69-vBJtvIf0"
   },
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHSdQPNUvIf0",
    "outputId": "0afbfb52-aebb-45c6-9420-f5f68f51e995",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 1.3678 - accuracy: 0.4459\n",
      "Epoch 1: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 2s 10ms/step - loss: 1.3663 - accuracy: 0.4486 - val_loss: 1.3530 - val_accuracy: 0.5506\n",
      "Epoch 2/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 1.3449 - accuracy: 0.5036\n",
      "Epoch 2: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3425 - accuracy: 0.5010 - val_loss: 1.3221 - val_accuracy: 0.5853\n",
      "Epoch 3/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 1.3123 - accuracy: 0.5181\n",
      "Epoch 3: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.3123 - accuracy: 0.5179 - val_loss: 1.2874 - val_accuracy: 0.6065\n",
      "Epoch 4/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 1.2845 - accuracy: 0.5384\n",
      "Epoch 4: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.2809 - accuracy: 0.5425 - val_loss: 1.2511 - val_accuracy: 0.6261\n",
      "Epoch 5/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 1.2531 - accuracy: 0.5366\n",
      "Epoch 5: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.2484 - accuracy: 0.5466 - val_loss: 1.2101 - val_accuracy: 0.6526\n",
      "Epoch 6/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 1.2176 - accuracy: 0.5469\n",
      "Epoch 6: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.2115 - accuracy: 0.5589 - val_loss: 1.1645 - val_accuracy: 0.6828\n",
      "Epoch 7/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 1.1722 - accuracy: 0.5700\n",
      "Epoch 7: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.1677 - accuracy: 0.5702 - val_loss: 1.1160 - val_accuracy: 0.6813\n",
      "Epoch 8/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 1.1331 - accuracy: 0.5815\n",
      "Epoch 8: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1308 - accuracy: 0.5811 - val_loss: 1.0716 - val_accuracy: 0.7424\n",
      "Epoch 9/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 1.1088 - accuracy: 0.5970\n",
      "Epoch 9: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1002 - accuracy: 0.5999 - val_loss: 1.0271 - val_accuracy: 0.7734\n",
      "Epoch 10/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 1.0676 - accuracy: 0.6140\n",
      "Epoch 10: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0656 - accuracy: 0.6115 - val_loss: 0.9831 - val_accuracy: 0.8066\n",
      "Epoch 11/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 1.0287 - accuracy: 0.6264\n",
      "Epoch 11: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0314 - accuracy: 0.6208 - val_loss: 0.9366 - val_accuracy: 0.8104\n",
      "Epoch 12/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.9972 - accuracy: 0.6328\n",
      "Epoch 12: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9960 - accuracy: 0.6302 - val_loss: 0.8944 - val_accuracy: 0.8308\n",
      "Epoch 13/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.9746 - accuracy: 0.6353\n",
      "Epoch 13: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9737 - accuracy: 0.6324 - val_loss: 0.8591 - val_accuracy: 0.7998\n",
      "Epoch 14/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.9467 - accuracy: 0.6367\n",
      "Epoch 14: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9457 - accuracy: 0.6334 - val_loss: 0.8223 - val_accuracy: 0.8361\n",
      "Epoch 15/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.9261 - accuracy: 0.6401\n",
      "Epoch 15: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9231 - accuracy: 0.6395 - val_loss: 0.7889 - val_accuracy: 0.8708\n",
      "Epoch 16/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.9018 - accuracy: 0.6449\n",
      "Epoch 16: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.9020 - accuracy: 0.6438 - val_loss: 0.7868 - val_accuracy: 0.8724\n",
      "Epoch 17/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.8898 - accuracy: 0.6549\n",
      "Epoch 17: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8834 - accuracy: 0.6601 - val_loss: 0.7547 - val_accuracy: 0.8935\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.8579 - accuracy: 0.6679\n",
      "Epoch 18: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8579 - accuracy: 0.6679 - val_loss: 0.7275 - val_accuracy: 0.9033\n",
      "Epoch 19/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.8467 - accuracy: 0.6790\n",
      "Epoch 19: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8482 - accuracy: 0.6689 - val_loss: 0.7248 - val_accuracy: 0.7636\n",
      "Epoch 20/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.8629 - accuracy: 0.6358\n",
      "Epoch 20: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8605 - accuracy: 0.6380 - val_loss: 0.6975 - val_accuracy: 0.8671\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.8272 - accuracy: 0.6594\n",
      "Epoch 21: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8272 - accuracy: 0.6594 - val_loss: 0.6771 - val_accuracy: 0.9026\n",
      "Epoch 22/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.8167 - accuracy: 0.6637\n",
      "Epoch 22: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.8108 - accuracy: 0.6682 - val_loss: 0.6595 - val_accuracy: 0.9056\n",
      "Epoch 23/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.8022 - accuracy: 0.6833\n",
      "Epoch 23: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.8028 - accuracy: 0.6833 - val_loss: 0.6381 - val_accuracy: 0.9116\n",
      "Epoch 24/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.7850 - accuracy: 0.6856\n",
      "Epoch 24: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7860 - accuracy: 0.6850 - val_loss: 0.6226 - val_accuracy: 0.9116\n",
      "Epoch 25/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.7729 - accuracy: 0.6967\n",
      "Epoch 25: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7698 - accuracy: 0.6971 - val_loss: 0.6185 - val_accuracy: 0.8557\n",
      "Epoch 26/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.7777 - accuracy: 0.6860\n",
      "Epoch 26: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7779 - accuracy: 0.6858 - val_loss: 0.5969 - val_accuracy: 0.9086\n",
      "Epoch 27/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.7667 - accuracy: 0.6973\n",
      "Epoch 27: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7664 - accuracy: 0.6974 - val_loss: 0.5853 - val_accuracy: 0.9147\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7478 - accuracy: 0.6976\n",
      "Epoch 28: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7478 - accuracy: 0.6976 - val_loss: 0.5686 - val_accuracy: 0.9313\n",
      "Epoch 29/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.7323 - accuracy: 0.7155\n",
      "Epoch 29: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7334 - accuracy: 0.7122 - val_loss: 0.5570 - val_accuracy: 0.9313\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7440 - accuracy: 0.7082\n",
      "Epoch 30: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7440 - accuracy: 0.7082 - val_loss: 0.5471 - val_accuracy: 0.9358\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7181 - accuracy: 0.7165\n",
      "Epoch 31: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7181 - accuracy: 0.7165 - val_loss: 0.5346 - val_accuracy: 0.9373\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7016 - accuracy: 0.7301\n",
      "Epoch 32: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7016 - accuracy: 0.7301 - val_loss: 0.5246 - val_accuracy: 0.9373\n",
      "Epoch 33/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.7153 - accuracy: 0.7119\n",
      "Epoch 33: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7150 - accuracy: 0.7120 - val_loss: 0.5138 - val_accuracy: 0.9373\n",
      "Epoch 34/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.7005 - accuracy: 0.7341\n",
      "Epoch 34: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7003 - accuracy: 0.7346 - val_loss: 0.5033 - val_accuracy: 0.9418\n",
      "Epoch 35/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.6712 - accuracy: 0.7395\n",
      "Epoch 35: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6741 - accuracy: 0.7367 - val_loss: 0.4947 - val_accuracy: 0.9350\n",
      "Epoch 36/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.6904 - accuracy: 0.7309\n",
      "Epoch 36: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.7283 - val_loss: 0.4877 - val_accuracy: 0.9358\n",
      "Epoch 37/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6863 - accuracy: 0.7308\n",
      "Epoch 37: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6861 - accuracy: 0.7311 - val_loss: 0.4787 - val_accuracy: 0.9418\n",
      "Epoch 38/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6871 - accuracy: 0.7329\n",
      "Epoch 38: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6867 - accuracy: 0.7331 - val_loss: 0.4718 - val_accuracy: 0.9335\n",
      "Epoch 39/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6803 - accuracy: 0.7328\n",
      "Epoch 39: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6824 - accuracy: 0.7321 - val_loss: 0.4634 - val_accuracy: 0.9411\n",
      "Epoch 40/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6768 - accuracy: 0.7404\n",
      "Epoch 40: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6761 - accuracy: 0.7399 - val_loss: 0.4580 - val_accuracy: 0.9373\n",
      "Epoch 41/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.6646 - accuracy: 0.7442\n",
      "Epoch 41: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6617 - accuracy: 0.7457 - val_loss: 0.4518 - val_accuracy: 0.9350\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6535 - accuracy: 0.7482\n",
      "Epoch 42: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6535 - accuracy: 0.7482 - val_loss: 0.4436 - val_accuracy: 0.9373\n",
      "Epoch 43/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.6548 - accuracy: 0.7464\n",
      "Epoch 43: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6548 - accuracy: 0.7477 - val_loss: 0.4370 - val_accuracy: 0.9456\n",
      "Epoch 44/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.6470 - accuracy: 0.7395\n",
      "Epoch 44: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6533 - accuracy: 0.7359 - val_loss: 0.4305 - val_accuracy: 0.9479\n",
      "Epoch 45/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.6352 - accuracy: 0.7545\n",
      "Epoch 45: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6419 - accuracy: 0.7510 - val_loss: 0.4274 - val_accuracy: 0.9343\n",
      "Epoch 46/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6624 - accuracy: 0.7393\n",
      "Epoch 46: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6626 - accuracy: 0.7394 - val_loss: 0.4235 - val_accuracy: 0.9358\n",
      "Epoch 47/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6485 - accuracy: 0.7409\n",
      "Epoch 47: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6488 - accuracy: 0.7409 - val_loss: 0.4180 - val_accuracy: 0.9479\n",
      "Epoch 48/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6257 - accuracy: 0.7651\n",
      "Epoch 48: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6245 - accuracy: 0.7651 - val_loss: 0.4127 - val_accuracy: 0.9471\n",
      "Epoch 49/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6438 - accuracy: 0.7510\n",
      "Epoch 49: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6433 - accuracy: 0.7513 - val_loss: 0.4056 - val_accuracy: 0.9539\n",
      "Epoch 50/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6264 - accuracy: 0.7568\n",
      "Epoch 50: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6264 - accuracy: 0.7563 - val_loss: 0.4024 - val_accuracy: 0.9464\n",
      "Epoch 51/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6191 - accuracy: 0.7629\n",
      "Epoch 51: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6192 - accuracy: 0.7628 - val_loss: 0.3996 - val_accuracy: 0.9441\n",
      "Epoch 52/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.6140 - accuracy: 0.7601\n",
      "Epoch 52: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6219 - accuracy: 0.7588 - val_loss: 0.3952 - val_accuracy: 0.9426\n",
      "Epoch 53/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.6348 - accuracy: 0.7538\n",
      "Epoch 53: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6297 - accuracy: 0.7550 - val_loss: 0.3916 - val_accuracy: 0.9471\n",
      "Epoch 54/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.6300 - accuracy: 0.7482\n",
      "Epoch 54: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6294 - accuracy: 0.7495 - val_loss: 0.3900 - val_accuracy: 0.9411\n",
      "Epoch 55/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6223 - accuracy: 0.7523\n",
      "Epoch 55: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6226 - accuracy: 0.7520 - val_loss: 0.3869 - val_accuracy: 0.9396\n",
      "Epoch 56/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.6112 - accuracy: 0.7608\n",
      "Epoch 56: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6122 - accuracy: 0.7603 - val_loss: 0.3806 - val_accuracy: 0.9486\n",
      "Epoch 57/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.6264 - accuracy: 0.7594\n",
      "Epoch 57: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6201 - accuracy: 0.7613 - val_loss: 0.3783 - val_accuracy: 0.9547\n",
      "Epoch 58/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.6066 - accuracy: 0.7722\n",
      "Epoch 58: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6104 - accuracy: 0.7689 - val_loss: 0.3747 - val_accuracy: 0.9502\n",
      "Epoch 59/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.6060 - accuracy: 0.7749\n",
      "Epoch 59: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6125 - accuracy: 0.7717 - val_loss: 0.3704 - val_accuracy: 0.9502\n",
      "Epoch 60/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.5875 - accuracy: 0.7749\n",
      "Epoch 60: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6016 - accuracy: 0.7701 - val_loss: 0.3665 - val_accuracy: 0.9562\n",
      "Epoch 61/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.6120 - accuracy: 0.7615\n",
      "Epoch 61: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6113 - accuracy: 0.7638 - val_loss: 0.3643 - val_accuracy: 0.9592\n",
      "Epoch 62/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.6019 - accuracy: 0.7704\n",
      "Epoch 62: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5992 - accuracy: 0.7691 - val_loss: 0.3615 - val_accuracy: 0.9585\n",
      "Epoch 63/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.6086 - accuracy: 0.7654\n",
      "Epoch 63: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6097 - accuracy: 0.7656 - val_loss: 0.3575 - val_accuracy: 0.9592\n",
      "Epoch 64/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.6148 - accuracy: 0.7613\n",
      "Epoch 64: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6106 - accuracy: 0.7631 - val_loss: 0.3583 - val_accuracy: 0.9539\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6019 - accuracy: 0.7679\n",
      "Epoch 65: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6019 - accuracy: 0.7679 - val_loss: 0.3554 - val_accuracy: 0.9547\n",
      "Epoch 66/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.5959 - accuracy: 0.7828\n",
      "Epoch 66: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5944 - accuracy: 0.7815 - val_loss: 0.3551 - val_accuracy: 0.9524\n",
      "Epoch 67/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5977 - accuracy: 0.7717\n",
      "Epoch 67: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5977 - accuracy: 0.7717 - val_loss: 0.3484 - val_accuracy: 0.9600\n",
      "Epoch 68/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5885 - accuracy: 0.7880\n",
      "Epoch 68: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5878 - accuracy: 0.7832 - val_loss: 0.3462 - val_accuracy: 0.9600\n",
      "Epoch 69/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5871 - accuracy: 0.7770\n",
      "Epoch 69: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5867 - accuracy: 0.7772 - val_loss: 0.3419 - val_accuracy: 0.9607\n",
      "Epoch 70/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.5837 - accuracy: 0.7713\n",
      "Epoch 70: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5868 - accuracy: 0.7691 - val_loss: 0.3433 - val_accuracy: 0.9547\n",
      "Epoch 71/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.5894 - accuracy: 0.7772\n",
      "Epoch 71: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5938 - accuracy: 0.7742 - val_loss: 0.3410 - val_accuracy: 0.9585\n",
      "Epoch 72/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.5762 - accuracy: 0.7833\n",
      "Epoch 72: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5763 - accuracy: 0.7830 - val_loss: 0.3395 - val_accuracy: 0.9585\n",
      "Epoch 73/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.5839 - accuracy: 0.7818\n",
      "Epoch 73: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5794 - accuracy: 0.7835 - val_loss: 0.3376 - val_accuracy: 0.9569\n",
      "Epoch 74/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5872 - accuracy: 0.7715\n",
      "Epoch 74: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5853 - accuracy: 0.7729 - val_loss: 0.3344 - val_accuracy: 0.9600\n",
      "Epoch 75/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.5690 - accuracy: 0.7798\n",
      "Epoch 75: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5686 - accuracy: 0.7815 - val_loss: 0.3310 - val_accuracy: 0.9615\n",
      "Epoch 76/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5852 - accuracy: 0.7683\n",
      "Epoch 76: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5777 - accuracy: 0.7727 - val_loss: 0.3281 - val_accuracy: 0.9622\n",
      "Epoch 77/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5780 - accuracy: 0.7830\n",
      "Epoch 77: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5780 - accuracy: 0.7832 - val_loss: 0.3282 - val_accuracy: 0.9585\n",
      "Epoch 78/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.5556 - accuracy: 0.7842\n",
      "Epoch 78: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5605 - accuracy: 0.7817 - val_loss: 0.3247 - val_accuracy: 0.9607\n",
      "Epoch 79/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.5884 - accuracy: 0.7726\n",
      "Epoch 79: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5807 - accuracy: 0.7754 - val_loss: 0.3226 - val_accuracy: 0.9630\n",
      "Epoch 80/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.5852 - accuracy: 0.7821\n",
      "Epoch 80: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5748 - accuracy: 0.7865 - val_loss: 0.3247 - val_accuracy: 0.9622\n",
      "Epoch 81/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5699 - accuracy: 0.7806\n",
      "Epoch 81: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.5706 - accuracy: 0.7784 - val_loss: 0.3212 - val_accuracy: 0.9592\n",
      "Epoch 82/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5621 - accuracy: 0.7828\n",
      "Epoch 82: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5622 - accuracy: 0.7825 - val_loss: 0.3161 - val_accuracy: 0.9615\n",
      "Epoch 83/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.5615 - accuracy: 0.7867\n",
      "Epoch 83: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5612 - accuracy: 0.7842 - val_loss: 0.3154 - val_accuracy: 0.9592\n",
      "Epoch 84/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5693 - accuracy: 0.7881\n",
      "Epoch 84: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5684 - accuracy: 0.7827 - val_loss: 0.3118 - val_accuracy: 0.9622\n",
      "Epoch 85/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5987 - accuracy: 0.7721\n",
      "Epoch 85: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5876 - accuracy: 0.7747 - val_loss: 0.3122 - val_accuracy: 0.9630\n",
      "Epoch 86/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.5777 - accuracy: 0.7766\n",
      "Epoch 86: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5687 - accuracy: 0.7827 - val_loss: 0.3114 - val_accuracy: 0.9615\n",
      "Epoch 87/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5592 - accuracy: 0.7820\n",
      "Epoch 87: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5603 - accuracy: 0.7817 - val_loss: 0.3121 - val_accuracy: 0.9622\n",
      "Epoch 88/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5660 - accuracy: 0.7891\n",
      "Epoch 88: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5652 - accuracy: 0.7888 - val_loss: 0.3125 - val_accuracy: 0.9645\n",
      "Epoch 89/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.5720 - accuracy: 0.7820\n",
      "Epoch 89: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5681 - accuracy: 0.7815 - val_loss: 0.3094 - val_accuracy: 0.9615\n",
      "Epoch 90/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5422 - accuracy: 0.7990\n",
      "Epoch 90: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5432 - accuracy: 0.7976 - val_loss: 0.3055 - val_accuracy: 0.9622\n",
      "Epoch 91/1000\n",
      "20/32 [=================>............] - ETA: 0s - loss: 0.5577 - accuracy: 0.7855\n",
      "Epoch 91: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5588 - accuracy: 0.7850 - val_loss: 0.3058 - val_accuracy: 0.9622\n",
      "Epoch 92/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.5595 - accuracy: 0.7767\n",
      "Epoch 92: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5599 - accuracy: 0.7767 - val_loss: 0.3057 - val_accuracy: 0.9630\n",
      "Epoch 93/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.5616 - accuracy: 0.7846\n",
      "Epoch 93: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5608 - accuracy: 0.7845 - val_loss: 0.3040 - val_accuracy: 0.9630\n",
      "Epoch 94/1000\n",
      "21/32 [==================>...........] - ETA: 0s - loss: 0.5446 - accuracy: 0.7891\n",
      "Epoch 94: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5581 - accuracy: 0.7878 - val_loss: 0.3009 - val_accuracy: 0.9645\n",
      "Epoch 95/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.5504 - accuracy: 0.7918\n",
      "Epoch 95: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5566 - accuracy: 0.7875 - val_loss: 0.2999 - val_accuracy: 0.9630\n",
      "Epoch 96/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.5542 - accuracy: 0.7842\n",
      "Epoch 96: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5503 - accuracy: 0.7868 - val_loss: 0.2995 - val_accuracy: 0.9660\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5523 - accuracy: 0.7845\n",
      "Epoch 97: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5523 - accuracy: 0.7845 - val_loss: 0.2998 - val_accuracy: 0.9660\n",
      "Epoch 98/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5706 - accuracy: 0.7802\n",
      "Epoch 98: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5618 - accuracy: 0.7863 - val_loss: 0.3007 - val_accuracy: 0.9645\n",
      "Epoch 99/1000\n",
      "20/32 [=================>............] - ETA: 0s - loss: 0.5427 - accuracy: 0.8023\n",
      "Epoch 99: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5378 - accuracy: 0.7981 - val_loss: 0.2957 - val_accuracy: 0.9622\n",
      "Epoch 100/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.5454 - accuracy: 0.7847\n",
      "Epoch 100: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5501 - accuracy: 0.7865 - val_loss: 0.2942 - val_accuracy: 0.9637\n",
      "Epoch 101/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5453 - accuracy: 0.7981\n",
      "Epoch 101: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5453 - accuracy: 0.7981 - val_loss: 0.2931 - val_accuracy: 0.9630\n",
      "Epoch 102/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5479 - accuracy: 0.7894\n",
      "Epoch 102: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5498 - accuracy: 0.7860 - val_loss: 0.2907 - val_accuracy: 0.9637\n",
      "Epoch 103/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5360 - accuracy: 0.7880\n",
      "Epoch 103: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5384 - accuracy: 0.7888 - val_loss: 0.2909 - val_accuracy: 0.9630\n",
      "Epoch 104/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5419 - accuracy: 0.7934\n",
      "Epoch 104: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5385 - accuracy: 0.7925 - val_loss: 0.2885 - val_accuracy: 0.9630\n",
      "Epoch 105/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5360 - accuracy: 0.7925\n",
      "Epoch 105: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5311 - accuracy: 0.7958 - val_loss: 0.2845 - val_accuracy: 0.9660\n",
      "Epoch 106/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5404 - accuracy: 0.7896\n",
      "Epoch 106: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5429 - accuracy: 0.7878 - val_loss: 0.2843 - val_accuracy: 0.9675\n",
      "Epoch 107/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5448 - accuracy: 0.7979\n",
      "Epoch 107: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5449 - accuracy: 0.7978 - val_loss: 0.2849 - val_accuracy: 0.9622\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5489 - accuracy: 0.7888\n",
      "Epoch 108: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5489 - accuracy: 0.7888 - val_loss: 0.2821 - val_accuracy: 0.9668\n",
      "Epoch 109/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.5437 - accuracy: 0.7879\n",
      "Epoch 109: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5448 - accuracy: 0.7913 - val_loss: 0.2836 - val_accuracy: 0.9645\n",
      "Epoch 110/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5455 - accuracy: 0.7948\n",
      "Epoch 110: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5490 - accuracy: 0.7933 - val_loss: 0.2841 - val_accuracy: 0.9615\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5557 - accuracy: 0.7890\n",
      "Epoch 111: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5557 - accuracy: 0.7890 - val_loss: 0.2856 - val_accuracy: 0.9630\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.7943\n",
      "Epoch 112: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5473 - accuracy: 0.7943 - val_loss: 0.2823 - val_accuracy: 0.9600\n",
      "Epoch 113/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.5492 - accuracy: 0.7913\n",
      "Epoch 113: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5480 - accuracy: 0.7918 - val_loss: 0.2854 - val_accuracy: 0.9600\n",
      "Epoch 114/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5453 - accuracy: 0.8064\n",
      "Epoch 114: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5306 - accuracy: 0.8056 - val_loss: 0.2832 - val_accuracy: 0.9622\n",
      "Epoch 115/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5445 - accuracy: 0.7911\n",
      "Epoch 115: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5318 - accuracy: 0.7961 - val_loss: 0.2779 - val_accuracy: 0.9637\n",
      "Epoch 116/1000\n",
      "20/32 [=================>............] - ETA: 0s - loss: 0.5377 - accuracy: 0.8012\n",
      "Epoch 116: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.8001 - val_loss: 0.2777 - val_accuracy: 0.9622\n",
      "Epoch 117/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5217 - accuracy: 0.7986\n",
      "Epoch 117: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.7946 - val_loss: 0.2793 - val_accuracy: 0.9615\n",
      "Epoch 118/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5313 - accuracy: 0.7959\n",
      "Epoch 118: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5319 - accuracy: 0.7948 - val_loss: 0.2757 - val_accuracy: 0.9637\n",
      "Epoch 119/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5419 - accuracy: 0.7959\n",
      "Epoch 119: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5464 - accuracy: 0.7943 - val_loss: 0.2757 - val_accuracy: 0.9637\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5405 - accuracy: 0.7925\n",
      "Epoch 120: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5405 - accuracy: 0.7925 - val_loss: 0.2784 - val_accuracy: 0.9645\n",
      "Epoch 121/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5200 - accuracy: 0.8043\n",
      "Epoch 121: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5246 - accuracy: 0.8006 - val_loss: 0.2758 - val_accuracy: 0.9637\n",
      "Epoch 122/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5331 - accuracy: 0.7860\n",
      "Epoch 122: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5323 - accuracy: 0.7915 - val_loss: 0.2747 - val_accuracy: 0.9637\n",
      "Epoch 123/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.5212 - accuracy: 0.7997\n",
      "Epoch 123: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5368 - accuracy: 0.7941 - val_loss: 0.2747 - val_accuracy: 0.9615\n",
      "Epoch 124/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5297 - accuracy: 0.7966\n",
      "Epoch 124: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5292 - accuracy: 0.7968 - val_loss: 0.2733 - val_accuracy: 0.9660\n",
      "Epoch 125/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5440 - accuracy: 0.7921\n",
      "Epoch 125: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.5411 - accuracy: 0.7943 - val_loss: 0.2744 - val_accuracy: 0.9637\n",
      "Epoch 126/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5481 - accuracy: 0.7953\n",
      "Epoch 126: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5478 - accuracy: 0.7953 - val_loss: 0.2767 - val_accuracy: 0.9653\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5116 - accuracy: 0.8061\n",
      "Epoch 127: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5116 - accuracy: 0.8061 - val_loss: 0.2710 - val_accuracy: 0.9668\n",
      "Epoch 128/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5494 - accuracy: 0.7862\n",
      "Epoch 128: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5387 - accuracy: 0.7915 - val_loss: 0.2709 - val_accuracy: 0.9653\n",
      "Epoch 129/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5129 - accuracy: 0.8021\n",
      "Epoch 129: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5166 - accuracy: 0.8006 - val_loss: 0.2713 - val_accuracy: 0.9615\n",
      "Epoch 130/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.5446 - accuracy: 0.7912\n",
      "Epoch 130: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5380 - accuracy: 0.7938 - val_loss: 0.2728 - val_accuracy: 0.9600\n",
      "Epoch 131/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5279 - accuracy: 0.7868\n",
      "Epoch 131: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5335 - accuracy: 0.7863 - val_loss: 0.2714 - val_accuracy: 0.9622\n",
      "Epoch 132/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.5101 - accuracy: 0.8118\n",
      "Epoch 132: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5200 - accuracy: 0.8074 - val_loss: 0.2675 - val_accuracy: 0.9637\n",
      "Epoch 133/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5325 - accuracy: 0.8034\n",
      "Epoch 133: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5224 - accuracy: 0.8079 - val_loss: 0.2689 - val_accuracy: 0.9592\n",
      "Epoch 134/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5364 - accuracy: 0.7969\n",
      "Epoch 134: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5291 - accuracy: 0.8001 - val_loss: 0.2671 - val_accuracy: 0.9585\n",
      "Epoch 135/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5036 - accuracy: 0.8076\n",
      "Epoch 135: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5130 - accuracy: 0.8069 - val_loss: 0.2633 - val_accuracy: 0.9653\n",
      "Epoch 136/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.4957 - accuracy: 0.8079\n",
      "Epoch 136: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.8046 - val_loss: 0.2640 - val_accuracy: 0.9637\n",
      "Epoch 137/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5052 - accuracy: 0.8135\n",
      "Epoch 137: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5062 - accuracy: 0.8122 - val_loss: 0.2614 - val_accuracy: 0.9637\n",
      "Epoch 138/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5249 - accuracy: 0.7984\n",
      "Epoch 138: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5243 - accuracy: 0.7983 - val_loss: 0.2615 - val_accuracy: 0.9645\n",
      "Epoch 139/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5132 - accuracy: 0.8063\n",
      "Epoch 139: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5135 - accuracy: 0.8066 - val_loss: 0.2598 - val_accuracy: 0.9675\n",
      "Epoch 140/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5162 - accuracy: 0.8047\n",
      "Epoch 140: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5101 - accuracy: 0.8066 - val_loss: 0.2598 - val_accuracy: 0.9645\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5218 - accuracy: 0.7941\n",
      "Epoch 141: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5218 - accuracy: 0.7941 - val_loss: 0.2588 - val_accuracy: 0.9660\n",
      "Epoch 142/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5081 - accuracy: 0.8139\n",
      "Epoch 142: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5144 - accuracy: 0.8094 - val_loss: 0.2590 - val_accuracy: 0.9637\n",
      "Epoch 143/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.5018 - accuracy: 0.8061\n",
      "Epoch 143: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5084 - accuracy: 0.8056 - val_loss: 0.2569 - val_accuracy: 0.9637\n",
      "Epoch 144/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5189 - accuracy: 0.8017\n",
      "Epoch 144: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5189 - accuracy: 0.8016 - val_loss: 0.2570 - val_accuracy: 0.9637\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5204 - accuracy: 0.8029\n",
      "Epoch 145: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5204 - accuracy: 0.8029 - val_loss: 0.2553 - val_accuracy: 0.9668\n",
      "Epoch 146/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.5290 - accuracy: 0.8083\n",
      "Epoch 146: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5271 - accuracy: 0.8072 - val_loss: 0.2617 - val_accuracy: 0.9622\n",
      "Epoch 147/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.5067 - accuracy: 0.8093\n",
      "Epoch 147: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5084 - accuracy: 0.8102 - val_loss: 0.2588 - val_accuracy: 0.9637\n",
      "Epoch 148/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5295 - accuracy: 0.7956\n",
      "Epoch 148: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5280 - accuracy: 0.7958 - val_loss: 0.2602 - val_accuracy: 0.9622\n",
      "Epoch 149/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.5088 - accuracy: 0.8086\n",
      "Epoch 149: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5117 - accuracy: 0.8079 - val_loss: 0.2587 - val_accuracy: 0.9630\n",
      "Epoch 150/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5092 - accuracy: 0.8150\n",
      "Epoch 150: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5045 - accuracy: 0.8170 - val_loss: 0.2588 - val_accuracy: 0.9630\n",
      "Epoch 151/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5341 - accuracy: 0.7949\n",
      "Epoch 151: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5343 - accuracy: 0.7951 - val_loss: 0.2578 - val_accuracy: 0.9660\n",
      "Epoch 152/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5246 - accuracy: 0.7903\n",
      "Epoch 152: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5194 - accuracy: 0.7948 - val_loss: 0.2566 - val_accuracy: 0.9653\n",
      "Epoch 153/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5038 - accuracy: 0.8060\n",
      "Epoch 153: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5090 - accuracy: 0.8059 - val_loss: 0.2560 - val_accuracy: 0.9637\n",
      "Epoch 154/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5408 - accuracy: 0.7858\n",
      "Epoch 154: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5333 - accuracy: 0.7925 - val_loss: 0.2547 - val_accuracy: 0.9668\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4986 - accuracy: 0.8142\n",
      "Epoch 155: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4986 - accuracy: 0.8142 - val_loss: 0.2535 - val_accuracy: 0.9660\n",
      "Epoch 156/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5153 - accuracy: 0.8135\n",
      "Epoch 156: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5099 - accuracy: 0.8147 - val_loss: 0.2529 - val_accuracy: 0.9645\n",
      "Epoch 157/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5010 - accuracy: 0.8089\n",
      "Epoch 157: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4981 - accuracy: 0.8089 - val_loss: 0.2526 - val_accuracy: 0.9637\n",
      "Epoch 158/1000\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.5064 - accuracy: 0.8110\n",
      "Epoch 158: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5054 - accuracy: 0.8092 - val_loss: 0.2522 - val_accuracy: 0.9653\n",
      "Epoch 159/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5120 - accuracy: 0.8031\n",
      "Epoch 159: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5103 - accuracy: 0.8056 - val_loss: 0.2522 - val_accuracy: 0.9645\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5097 - accuracy: 0.8072\n",
      "Epoch 160: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5097 - accuracy: 0.8072 - val_loss: 0.2494 - val_accuracy: 0.9660\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.8021\n",
      "Epoch 161: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.5050 - accuracy: 0.8021 - val_loss: 0.2494 - val_accuracy: 0.9668\n",
      "Epoch 162/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.4877 - accuracy: 0.8101\n",
      "Epoch 162: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4998 - accuracy: 0.8084 - val_loss: 0.2503 - val_accuracy: 0.9653\n",
      "Epoch 163/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5075 - accuracy: 0.8059\n",
      "Epoch 163: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5074 - accuracy: 0.8061 - val_loss: 0.2513 - val_accuracy: 0.9637\n",
      "Epoch 164/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5036 - accuracy: 0.8107\n",
      "Epoch 164: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5032 - accuracy: 0.8109 - val_loss: 0.2496 - val_accuracy: 0.9637\n",
      "Epoch 165/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5246 - accuracy: 0.7964\n",
      "Epoch 165: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5227 - accuracy: 0.7981 - val_loss: 0.2506 - val_accuracy: 0.9630\n",
      "Epoch 166/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5141 - accuracy: 0.7994\n",
      "Epoch 166: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5178 - accuracy: 0.8004 - val_loss: 0.2494 - val_accuracy: 0.9645\n",
      "Epoch 167/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5158 - accuracy: 0.8053\n",
      "Epoch 167: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5264 - accuracy: 0.8004 - val_loss: 0.2493 - val_accuracy: 0.9653\n",
      "Epoch 168/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.5133 - accuracy: 0.8129\n",
      "Epoch 168: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5135 - accuracy: 0.8137 - val_loss: 0.2500 - val_accuracy: 0.9675\n",
      "Epoch 169/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.5113 - accuracy: 0.8011\n",
      "Epoch 169: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5178 - accuracy: 0.8044 - val_loss: 0.2494 - val_accuracy: 0.9668\n",
      "Epoch 170/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.5033 - accuracy: 0.8102\n",
      "Epoch 170: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4980 - accuracy: 0.8122 - val_loss: 0.2483 - val_accuracy: 0.9668\n",
      "Epoch 171/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.4991 - accuracy: 0.8114\n",
      "Epoch 171: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5070 - accuracy: 0.8054 - val_loss: 0.2477 - val_accuracy: 0.9653\n",
      "Epoch 172/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5056 - accuracy: 0.8077\n",
      "Epoch 172: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5117 - accuracy: 0.8066 - val_loss: 0.2500 - val_accuracy: 0.9622\n",
      "Epoch 173/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.5004 - accuracy: 0.8099\n",
      "Epoch 173: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5068 - accuracy: 0.8064 - val_loss: 0.2480 - val_accuracy: 0.9653\n",
      "Epoch 174/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5136 - accuracy: 0.8016\n",
      "Epoch 174: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5149 - accuracy: 0.7968 - val_loss: 0.2469 - val_accuracy: 0.9645\n",
      "Epoch 175/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.5006 - accuracy: 0.8066\n",
      "Epoch 175: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5056 - accuracy: 0.8056 - val_loss: 0.2482 - val_accuracy: 0.9653\n",
      "Epoch 176/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5059 - accuracy: 0.8148\n",
      "Epoch 176: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5058 - accuracy: 0.8150 - val_loss: 0.2508 - val_accuracy: 0.9653\n",
      "Epoch 177/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.5097 - accuracy: 0.8066\n",
      "Epoch 177: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.5090 - accuracy: 0.8072 - val_loss: 0.2477 - val_accuracy: 0.9668\n",
      "Epoch 178/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.5074 - accuracy: 0.8178\n",
      "Epoch 178: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5069 - accuracy: 0.8162 - val_loss: 0.2495 - val_accuracy: 0.9645\n",
      "Epoch 179/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.5142 - accuracy: 0.8050\n",
      "Epoch 179: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5156 - accuracy: 0.8031 - val_loss: 0.2477 - val_accuracy: 0.9653\n",
      "Epoch 180/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5041 - accuracy: 0.8057\n",
      "Epoch 180: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5012 - accuracy: 0.8069 - val_loss: 0.2467 - val_accuracy: 0.9653\n",
      "Epoch 181/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5218 - accuracy: 0.7961\n",
      "Epoch 181: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5186 - accuracy: 0.7963 - val_loss: 0.2475 - val_accuracy: 0.9607\n",
      "Epoch 182/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.5012 - accuracy: 0.8145\n",
      "Epoch 182: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5029 - accuracy: 0.8119 - val_loss: 0.2453 - val_accuracy: 0.9653\n",
      "Epoch 183/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.4992 - accuracy: 0.8112\n",
      "Epoch 183: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4993 - accuracy: 0.8097 - val_loss: 0.2439 - val_accuracy: 0.9653\n",
      "Epoch 184/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5042 - accuracy: 0.8179\n",
      "Epoch 184: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5015 - accuracy: 0.8157 - val_loss: 0.2424 - val_accuracy: 0.9668\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5031 - accuracy: 0.8139\n",
      "Epoch 185: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5031 - accuracy: 0.8139 - val_loss: 0.2441 - val_accuracy: 0.9637\n",
      "Epoch 186/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.5175 - accuracy: 0.8009\n",
      "Epoch 186: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5128 - accuracy: 0.8021 - val_loss: 0.2441 - val_accuracy: 0.9668\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4919 - accuracy: 0.8185\n",
      "Epoch 187: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4919 - accuracy: 0.8185 - val_loss: 0.2442 - val_accuracy: 0.9637\n",
      "Epoch 188/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.4986 - accuracy: 0.8120\n",
      "Epoch 188: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4977 - accuracy: 0.8122 - val_loss: 0.2427 - val_accuracy: 0.9645\n",
      "Epoch 189/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.4935 - accuracy: 0.8111\n",
      "Epoch 189: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4894 - accuracy: 0.8152 - val_loss: 0.2406 - val_accuracy: 0.9660\n",
      "Epoch 190/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.5025 - accuracy: 0.8080\n",
      "Epoch 190: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5042 - accuracy: 0.8079 - val_loss: 0.2402 - val_accuracy: 0.9660\n",
      "Epoch 191/1000\n",
      "24/32 [=====================>........] - ETA: 0s - loss: 0.4964 - accuracy: 0.8154\n",
      "Epoch 191: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.8175 - val_loss: 0.2410 - val_accuracy: 0.9668\n",
      "Epoch 192/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5033 - accuracy: 0.8153\n",
      "Epoch 192: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5041 - accuracy: 0.8134 - val_loss: 0.2413 - val_accuracy: 0.9645\n",
      "Epoch 193/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5107 - accuracy: 0.8004\n",
      "Epoch 193: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5103 - accuracy: 0.8006 - val_loss: 0.2438 - val_accuracy: 0.9615\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5168 - accuracy: 0.8066\n",
      "Epoch 194: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5168 - accuracy: 0.8066 - val_loss: 0.2431 - val_accuracy: 0.9630\n",
      "Epoch 195/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.4928 - accuracy: 0.8086\n",
      "Epoch 195: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5030 - accuracy: 0.8049 - val_loss: 0.2416 - val_accuracy: 0.9653\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.8112\n",
      "Epoch 196: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4867 - accuracy: 0.8112 - val_loss: 0.2418 - val_accuracy: 0.9622\n",
      "Epoch 197/1000\n",
      "25/32 [======================>.......] - ETA: 0s - loss: 0.5040 - accuracy: 0.8066\n",
      "Epoch 197: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5043 - accuracy: 0.8069 - val_loss: 0.2425 - val_accuracy: 0.9630\n",
      "Epoch 198/1000\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.5099 - accuracy: 0.8065\n",
      "Epoch 198: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5078 - accuracy: 0.8069 - val_loss: 0.2428 - val_accuracy: 0.9653\n",
      "Epoch 199/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.4998 - accuracy: 0.8112\n",
      "Epoch 199: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5019 - accuracy: 0.8109 - val_loss: 0.2448 - val_accuracy: 0.9592\n",
      "Epoch 200/1000\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.5226 - accuracy: 0.8074\n",
      "Epoch 200: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5242 - accuracy: 0.8074 - val_loss: 0.2444 - val_accuracy: 0.9607\n",
      "Epoch 201/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.5009 - accuracy: 0.8125\n",
      "Epoch 201: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5009 - accuracy: 0.8127 - val_loss: 0.2449 - val_accuracy: 0.9607\n",
      "Epoch 202/1000\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.4809 - accuracy: 0.8186\n",
      "Epoch 202: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4820 - accuracy: 0.8187 - val_loss: 0.2444 - val_accuracy: 0.9592\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5026 - accuracy: 0.8097\n",
      "Epoch 203: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5026 - accuracy: 0.8097 - val_loss: 0.2416 - val_accuracy: 0.9660\n",
      "Epoch 204/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.4910 - accuracy: 0.8201\n",
      "Epoch 204: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4907 - accuracy: 0.8202 - val_loss: 0.2412 - val_accuracy: 0.9660\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5012 - accuracy: 0.8056\n",
      "Epoch 205: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.5012 - accuracy: 0.8056 - val_loss: 0.2404 - val_accuracy: 0.9660\n",
      "Epoch 206/1000\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.5131 - accuracy: 0.8101\n",
      "Epoch 206: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5136 - accuracy: 0.8092 - val_loss: 0.2441 - val_accuracy: 0.9607\n",
      "Epoch 207/1000\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.4989 - accuracy: 0.8099\n",
      "Epoch 207: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5000 - accuracy: 0.8084 - val_loss: 0.2452 - val_accuracy: 0.9607\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.8112\n",
      "Epoch 208: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4843 - accuracy: 0.8112 - val_loss: 0.2409 - val_accuracy: 0.9653\n",
      "Epoch 209/1000\n",
      "31/32 [============================>.] - ETA: 0s - loss: 0.4913 - accuracy: 0.8097\n",
      "Epoch 209: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4915 - accuracy: 0.8097 - val_loss: 0.2421 - val_accuracy: 0.9615\n",
      "Epoch 210/1000\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.4825 - accuracy: 0.8161\n",
      "Epoch 210: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4922 - accuracy: 0.8084 - val_loss: 0.2413 - val_accuracy: 0.9607\n",
      "Epoch 210: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x78050db82980>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "UndgdmVrvIf0"
   },
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "if USE_PRUNING:\n",
    "    import tensorflow_model_optimization as tfmot\n",
    "    with tfmot.sparsity.keras.prune_scope():\n",
    "        model = tf.keras.models.load_model(model_save_path)\n",
    "else:\n",
    "    model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-mNsRi9vIf0",
    "outputId": "f5746001-b70b-437b-adb5-29082c1bd715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step\n",
      "[0.9254498  0.02250926 0.0246009  0.02744014]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1crca9AvIf1"
   },
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2_-4Z6gxdjr"
   },
   "source": [
    "## 1. 非LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "5jZ_v27IvIf1",
    "outputId": "b58c0015-bddb-4064-9bd2-023f681c3ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       395\n",
      "           1       0.94      0.99      0.96       295\n",
      "           2       0.94      0.98      0.96       307\n",
      "           3       0.97      0.87      0.92       327\n",
      "\n",
      "    accuracy                           0.96      1324\n",
      "   macro avg       0.96      0.96      0.96      1324\n",
      "weighted avg       0.96      0.96      0.96      1324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ri2DWcZxiK_"
   },
   "source": [
    "## 2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "6QMeLAWXxOn6",
    "outputId": "264bde3b-a727-4f7e-8719-110ca953627a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       395\n",
      "           1       0.94      0.99      0.96       295\n",
      "           2       0.94      0.98      0.96       307\n",
      "           3       0.97      0.87      0.92       327\n",
      "\n",
      "    accuracy                           0.96      1324\n",
      "   macro avg       0.96      0.96      0.96      1324\n",
      "weighted avg       0.96      0.96      0.96      1324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJuzeaNvvIf1"
   },
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to model/point_history_classifier/point_history_classifier.hdf5\n"
     ]
    }
   ],
   "source": [
    "# Save model without optimizer for conversion\n",
    "model.save(model_save_path, include_optimizer=False)\n",
    "print(f\"Saved model to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representative dataset generator for INT8 quantization\n",
    "def representative_dataset_gen():\n",
    "    \"\"\"Generate representative dataset for INT8 quantization (sequence data).\"\"\"\n",
    "    for i in range(min(100, len(X_train))):\n",
    "        # Reshape for LSTM if needed\n",
    "        yield [X_train[i:i+1].astype(np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting Model Export Process\n",
      "============================================================\n",
      "\n",
      "[4/5] Exporting INT8 with Pruning...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpkccl40uj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkccl40uj/assets\n",
      "/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2026-01-07 16:43:09.227752: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2026-01-07 16:43:09.227802: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2026-01-07 16:43:09.227978: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpkccl40uj\n",
      "2026-01-07 16:43:09.228910: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2026-01-07 16:43:09.228923: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpkccl40uj\n",
      "2026-01-07 16:43:09.230756: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2026-01-07 16:43:09.241015: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpkccl40uj\n",
      "2026-01-07 16:43:09.246778: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 18793 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved: model/point_history_classifier/point_history_classifier_int8_pruned.tflite (4056 bytes)\n",
      "    Attempting Edge TPU compilation...\n",
      "    ✓ Edge TPU model: model/point_history_classifier/point_history_classifier_int8_pruned_edgetpu.tflite\n",
      "\n",
      "[5/5] Exporting FP16 with Pruning...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpe4axbrxo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe4axbrxo/assets\n",
      "2026-01-07 16:43:09.986958: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2026-01-07 16:43:09.986980: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2026-01-07 16:43:09.987080: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpe4axbrxo\n",
      "2026-01-07 16:43:09.987703: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2026-01-07 16:43:09.987714: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpe4axbrxo\n",
      "2026-01-07 16:43:09.989816: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2026-01-07 16:43:10.001861: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpe4axbrxo\n",
      "2026-01-07 16:43:10.005723: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 18643 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved: model/point_history_classifier/point_history_classifier_fp16_pruned.tflite (5208 bytes)\n",
      "\n",
      "[5/5] FP16 with Pruning requires retraining with pruning enabled.\n",
      "  ℹ Set up pruning before training and re-run this notebook.\n",
      "\n",
      "============================================================\n",
      "Export Complete! Generated 1 model(s):\n",
      "============================================================\n",
      "  • point_history_classifier_int8_pruned_edgetpu.tflite: 40.59 KB\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "exported_models = []\n",
    "base_path = \"model/point_history_classifier/point_history_classifier\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Starting Model Export Process\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Dynamic Range Quantization (Default)\n",
    "# 1. Dynamic Range Quantization (Default)\n",
    "if EXPORT_DYNAMIC:\n",
    "    print(\"\\n[1/5] Exporting Dynamic Range Quantization...\")\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    \n",
    "    # Handle LSTM models - allow SELECT_TF_OPS for dynamic operations\n",
    "    converter.target_spec.supported_ops = [\n",
    "        tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "        tf.lite.OpsSet.SELECT_TF_OPS  # Required for LSTM\n",
    "    ]\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    save_path = f\"{base_path}.tflite\"\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "    exported_models.append(save_path)\n",
    "    print(f\"  ✓ Saved: {save_path} ({len(tflite_model)} bytes)\")\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    save_path = f\"{base_path}.tflite\"\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f\"  ✓ Saved: {save_path} ({len(tflite_model)} bytes)\")\n",
    "\n",
    "# 2. INT8 Full Quantization\n",
    "if EXPORT_INT8_FULL:\n",
    "    print(\"\\n[2/5] Exporting INT8 Full Quantization...\")\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_dataset_gen\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    save_path = f\"{base_path}_int8.tflite\"\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f\"  ✓ Saved: {save_path} ({len(tflite_model)} bytes)\")\n",
    "    \n",
    "    # Try Edge TPU compilation\n",
    "    if COMPILE_EDGE_TPU:\n",
    "        print(\"    Attempting Edge TPU compilation...\")\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [\"edgetpu_compiler\", save_path, \"-o\", \"model/point_history_classifier\"],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=30\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                edgetpu_path = f\"{base_path}_int8_edgetpu.tflite\"\n",
    "                if os.path.exists(edgetpu_path):\n",
    "                    exported_models.append(edgetpu_path)\n",
    "                    print(f\"    ✓ Edge TPU model: {edgetpu_path}\")\n",
    "            else:\n",
    "                print(f\"    ⚠ Edge TPU compilation failed: {result.stderr}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"    ⚠ edgetpu_compiler not found. Install from: https://coral.ai/docs/edgetpu/compiler/\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ⚠ Edge TPU compilation error: {e}\")\n",
    "\n",
    "# 3. FP16 Quantization\n",
    "if EXPORT_FP16:\n",
    "    print(\"\\n[3/5] Exporting FP16 Quantization...\")\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    save_path = f\"{base_path}_fp16.tflite\"\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f\"  ✓ Saved: {save_path} ({len(tflite_model)} bytes)\")\n",
    "\n",
    "# 4. INT8 with Pruning\n",
    "if EXPORT_INT8_PRUNED:\n",
    "    if USE_PRUNING:\n",
    "        print(\"\\n[4/5] Exporting INT8 with Pruning...\")\n",
    "        import tensorflow_model_optimization as tfmot\n",
    "        model_for_export = tfmot.sparsity.keras.strip_pruning(model)\n",
    "        \n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.representative_dataset = representative_dataset_gen\n",
    "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "        converter.inference_input_type = tf.uint8\n",
    "        converter.inference_output_type = tf.uint8\n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        save_path = f\"{base_path}_int8_pruned.tflite\"\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"  ✓ Saved: {save_path} ({len(tflite_model)} bytes)\")\n",
    "        \n",
    "        if COMPILE_EDGE_TPU:\n",
    "            print(\"    Attempting Edge TPU compilation...\")\n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    [\"edgetpu_compiler\", save_path, \"-o\", \"model/point_history_classifier\"],\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                    timeout=30\n",
    "                )\n",
    "                if result.returncode == 0:\n",
    "                    edgetpu_path = f\"{base_path}_int8_pruned_edgetpu.tflite\"\n",
    "                    if os.path.exists(edgetpu_path):\n",
    "                        exported_models.append(edgetpu_path)\n",
    "                        print(f\"    ✓ Edge TPU model: {edgetpu_path}\")\n",
    "                else:\n",
    "                    print(f\"    ⚠ Edge TPU compilation failed: {result.stderr}\")\n",
    "            except FileNotFoundError:\n",
    "                print(\"    ⚠ edgetpu_compiler not found\")\n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠ Edge TPU compilation error: {e}\")\n",
    "    else:\n",
    "        print(\"\\n[4/5] INT8 with Pruning requires training with pruning enabled.\")\n",
    "        print(\"  ℹ Set EXPORT_INT8_PRUNED=True and re-run training.\")\n",
    "\n",
    "# 5. FP16 with Pruning\n",
    "if EXPORT_FP16_PRUNED:\n",
    "    if USE_PRUNING:\n",
    "        print(\"\\n[5/5] Exporting FP16 with Pruning...\")\n",
    "        import tensorflow_model_optimization as tfmot\n",
    "        model_for_export = tfmot.sparsity.keras.strip_pruning(model)\n",
    "        \n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "        tflite_model = converter.convert()\n",
    "        \n",
    "        save_path = f\"{base_path}_fp16_pruned.tflite\"\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"  ✓ Saved: {save_path} ({len(tflite_model)} bytes)\")\n",
    "    else:\n",
    "        print(\"\\n[5/5] FP16 with Pruning requires training with pruning enabled.\")\n",
    "        print(\"  ℹ Set EXPORT_FP16_PRUNED=True and re-run training.\")\n",
    "\n",
    "if EXPORT_FP16_PRUNED:\n",
    "    print(\"\\n[5/5] FP16 with Pruning requires retraining with pruning enabled.\")\n",
    "    print(\"  ℹ Set up pruning before training and re-run this notebook.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Export Complete! Generated {len(exported_models)} model(s):\")\n",
    "print(\"=\" * 60)\n",
    "for model_path in exported_models:\n",
    "    size_kb = os.path.getsize(model_path) / 1024\n",
    "    print(f\"  • {os.path.basename(model_path)}: {size_kb:.2f} KB\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
