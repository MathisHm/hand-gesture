{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Wzu_rvVOvIft"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AcHvCTtvPrq",
        "outputId": "dcffe970-c837-4c3f-c5ab-15c74727e981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.10.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMJOOOb-vIfv"
      },
      "source": [
        "# 各パス指定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cJd8h9AuvIfw"
      },
      "outputs": [],
      "source": [
        "dataset = 'model/point_history_classifier/point_history.csv'\n",
        "model_save_path = 'model/point_history_classifier/point_history_classifier.hdf5'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvOgeU9ivIfw"
      },
      "source": [
        "# 分類数設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yym-K6cpvIfw"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYnBVymnvIfw"
      },
      "source": [
        "# 入力長"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hvSD8ZomvIfx"
      },
      "outputs": [],
      "source": [
        "TIME_STEPS = 16\n",
        "DIMENSION = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6xy5JETvIfx"
      },
      "source": [
        "# 学習データ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "OE4mDI5avIfx"
      },
      "outputs": [],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (TIME_STEPS * DIMENSION) + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "yR2EP-vevIfy"
      },
      "outputs": [],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wyJf3nVTvIfy"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1ec59e7vIfy"
      },
      "source": [
        "# モデル構築"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "SdvYbxIhvIfz"
      },
      "outputs": [],
      "source": [
        "use_lstm = True\n",
        "model = None\n",
        "\n",
        "if use_lstm:\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
        "        tf.keras.layers.Reshape((TIME_STEPS, DIMENSION), input_shape=(TIME_STEPS * DIMENSION, )), \n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        # tf.keras.layers.LSTM(16, input_shape=[TIME_STEPS, DIMENSION]),\n",
        "        tf.keras.layers.LSTM(16, time_major=False, return_sequences=True),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(10, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "else:\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(24, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(10, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldLE_fH0vIfz",
        "outputId": "da9b9b8e-a1e1-4b94-bdf8-6a2b63277b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 16, 2)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 2)             0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 16, 16)            1216      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                2570      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,830\n",
            "Trainable params: 3,830\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6tmmL_z8vIfz"
      },
      "outputs": [],
      "source": [
        "# モデルチェックポイントのコールバック\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False)\n",
        "# 早期打ち切り用コールバック\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "bqg4IRS_vIf0"
      },
      "outputs": [],
      "source": [
        "# モデルコンパイル\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x69-vBJtvIf0"
      },
      "source": [
        "# モデル訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHSdQPNUvIf0",
        "outputId": "0afbfb52-aebb-45c6-9420-f5f68f51e995",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 1.3800 - accuracy: 0.4471\n",
            "Epoch 1: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 2s 21ms/step - loss: 1.3799 - accuracy: 0.4466 - val_loss: 1.3734 - val_accuracy: 0.5038\n",
            "Epoch 2/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 1.3640 - accuracy: 0.4970\n",
            "Epoch 2: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.3630 - accuracy: 0.4960 - val_loss: 1.3492 - val_accuracy: 0.5174\n",
            "Epoch 3/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.3233 - accuracy: 0.5141\n",
            "Epoch 3: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.3233 - accuracy: 0.5141 - val_loss: 1.2959 - val_accuracy: 0.5053\n",
            "Epoch 4/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 1.2615 - accuracy: 0.5266\n",
            "Epoch 4: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.2604 - accuracy: 0.5262 - val_loss: 1.2316 - val_accuracy: 0.5914\n",
            "Epoch 5/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 1.1965 - accuracy: 0.5591\n",
            "Epoch 5: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 1.1951 - accuracy: 0.5624 - val_loss: 1.1395 - val_accuracy: 0.6465\n",
            "Epoch 6/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 1.1153 - accuracy: 0.5995\n",
            "Epoch 6: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 1.1132 - accuracy: 0.6027 - val_loss: 1.0994 - val_accuracy: 0.6873\n",
            "Epoch 7/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 1.0487 - accuracy: 0.6449\n",
            "Epoch 7: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0487 - accuracy: 0.6450 - val_loss: 0.9935 - val_accuracy: 0.7047\n",
            "Epoch 8/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.9626 - accuracy: 0.6469\n",
            "Epoch 8: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.9626 - accuracy: 0.6470 - val_loss: 0.8802 - val_accuracy: 0.7115\n",
            "Epoch 9/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.8567 - accuracy: 0.6613\n",
            "Epoch 9: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.8527 - accuracy: 0.6599 - val_loss: 0.7594 - val_accuracy: 0.6949\n",
            "Epoch 10/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.7646 - accuracy: 0.6721\n",
            "Epoch 10: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.7623 - accuracy: 0.6732 - val_loss: 0.6506 - val_accuracy: 0.7477\n",
            "Epoch 11/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.6879 - accuracy: 0.7060\n",
            "Epoch 11: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6843 - accuracy: 0.7080 - val_loss: 0.5880 - val_accuracy: 0.7802\n",
            "Epoch 12/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.6491 - accuracy: 0.7213\n",
            "Epoch 12: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.6488 - accuracy: 0.7216 - val_loss: 0.5491 - val_accuracy: 0.7931\n",
            "Epoch 13/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.6071 - accuracy: 0.7428\n",
            "Epoch 13: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6011 - accuracy: 0.7450 - val_loss: 0.5316 - val_accuracy: 0.7968\n",
            "Epoch 14/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.5867 - accuracy: 0.7521\n",
            "Epoch 14: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.5850 - accuracy: 0.7525 - val_loss: 0.5135 - val_accuracy: 0.8051\n",
            "Epoch 15/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.5828 - accuracy: 0.7586\n",
            "Epoch 15: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.5828 - accuracy: 0.7586 - val_loss: 0.4888 - val_accuracy: 0.8066\n",
            "Epoch 16/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.5416 - accuracy: 0.7700\n",
            "Epoch 16: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.5426 - accuracy: 0.7719 - val_loss: 0.4775 - val_accuracy: 0.8112\n",
            "Epoch 17/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.5274 - accuracy: 0.7800\n",
            "Epoch 17: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5274 - accuracy: 0.7800 - val_loss: 0.4579 - val_accuracy: 0.8157\n",
            "Epoch 18/1000\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.5198 - accuracy: 0.7791\n",
            "Epoch 18: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5162 - accuracy: 0.7815 - val_loss: 0.4416 - val_accuracy: 0.8263\n",
            "Epoch 19/1000\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.5082 - accuracy: 0.7876\n",
            "Epoch 19: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5087 - accuracy: 0.7883 - val_loss: 0.4415 - val_accuracy: 0.8218\n",
            "Epoch 20/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.4891 - accuracy: 0.8000\n",
            "Epoch 20: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.4930 - accuracy: 0.7983 - val_loss: 0.4193 - val_accuracy: 0.8369\n",
            "Epoch 21/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.4821 - accuracy: 0.8054\n",
            "Epoch 21: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.4821 - accuracy: 0.8054 - val_loss: 0.4327 - val_accuracy: 0.8240\n",
            "Epoch 22/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.4750 - accuracy: 0.8021\n",
            "Epoch 22: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4762 - accuracy: 0.8021 - val_loss: 0.3951 - val_accuracy: 0.8512\n",
            "Epoch 23/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.4746 - accuracy: 0.8106\n",
            "Epoch 23: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.4721 - accuracy: 0.8094 - val_loss: 0.3907 - val_accuracy: 0.8520\n",
            "Epoch 24/1000\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.4508 - accuracy: 0.8212\n",
            "Epoch 24: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.4502 - accuracy: 0.8215 - val_loss: 0.3896 - val_accuracy: 0.8437\n",
            "Epoch 25/1000\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.4354 - accuracy: 0.8319\n",
            "Epoch 25: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.4282 - accuracy: 0.8318 - val_loss: 0.3671 - val_accuracy: 0.8550\n",
            "Epoch 26/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.4408 - accuracy: 0.8284\n",
            "Epoch 26: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.4405 - accuracy: 0.8285 - val_loss: 0.3561 - val_accuracy: 0.8633\n",
            "Epoch 27/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.4213 - accuracy: 0.8435\n",
            "Epoch 27: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.4217 - accuracy: 0.8432 - val_loss: 0.3425 - val_accuracy: 0.8693\n",
            "Epoch 28/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.4069 - accuracy: 0.8524\n",
            "Epoch 28: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4070 - accuracy: 0.8507 - val_loss: 0.3317 - val_accuracy: 0.8860\n",
            "Epoch 29/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.3992 - accuracy: 0.8543\n",
            "Epoch 29: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3976 - accuracy: 0.8560 - val_loss: 0.3240 - val_accuracy: 0.8829\n",
            "Epoch 30/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.3825 - accuracy: 0.8564\n",
            "Epoch 30: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3823 - accuracy: 0.8565 - val_loss: 0.3179 - val_accuracy: 0.8822\n",
            "Epoch 31/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.3768 - accuracy: 0.8583\n",
            "Epoch 31: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.3726 - accuracy: 0.8608 - val_loss: 0.3054 - val_accuracy: 0.8852\n",
            "Epoch 32/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.3571 - accuracy: 0.8753\n",
            "Epoch 32: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.3623 - accuracy: 0.8721 - val_loss: 0.2921 - val_accuracy: 0.8912\n",
            "Epoch 33/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.3681 - accuracy: 0.8629\n",
            "Epoch 33: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3681 - accuracy: 0.8630 - val_loss: 0.2879 - val_accuracy: 0.8935\n",
            "Epoch 34/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.8754\n",
            "Epoch 34: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3406 - accuracy: 0.8754 - val_loss: 0.2786 - val_accuracy: 0.9003\n",
            "Epoch 35/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.3346 - accuracy: 0.8825\n",
            "Epoch 35: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.3365 - accuracy: 0.8799 - val_loss: 0.2641 - val_accuracy: 0.9079\n",
            "Epoch 36/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.3271 - accuracy: 0.8862\n",
            "Epoch 36: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.3279 - accuracy: 0.8870 - val_loss: 0.2610 - val_accuracy: 0.9109\n",
            "Epoch 37/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.3241 - accuracy: 0.8860\n",
            "Epoch 37: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.3275 - accuracy: 0.8862 - val_loss: 0.2724 - val_accuracy: 0.9252\n",
            "Epoch 38/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.3780 - accuracy: 0.8663\n",
            "Epoch 38: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.8703 - val_loss: 0.2556 - val_accuracy: 0.9252\n",
            "Epoch 39/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.3052 - accuracy: 0.8976\n",
            "Epoch 39: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.3106 - accuracy: 0.8948 - val_loss: 0.2425 - val_accuracy: 0.9245\n",
            "Epoch 40/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.3165 - accuracy: 0.8934\n",
            "Epoch 40: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 0.3165 - accuracy: 0.8935 - val_loss: 0.2329 - val_accuracy: 0.9298\n",
            "Epoch 41/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2937 - accuracy: 0.8994\n",
            "Epoch 41: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.2934 - accuracy: 0.8995 - val_loss: 0.2229 - val_accuracy: 0.9275\n",
            "Epoch 42/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.2991 - accuracy: 0.8970\n",
            "Epoch 42: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.3001 - accuracy: 0.8958 - val_loss: 0.2929 - val_accuracy: 0.9298\n",
            "Epoch 43/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.3602 - accuracy: 0.8623\n",
            "Epoch 43: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 0.3572 - accuracy: 0.8640 - val_loss: 0.2112 - val_accuracy: 0.9441\n",
            "Epoch 44/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.2831 - accuracy: 0.9120\n",
            "Epoch 44: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.2833 - accuracy: 0.9119 - val_loss: 0.2076 - val_accuracy: 0.9426\n",
            "Epoch 45/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.2928 - accuracy: 0.9038\n",
            "Epoch 45: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.2884 - accuracy: 0.9053 - val_loss: 0.2026 - val_accuracy: 0.9396\n",
            "Epoch 46/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9177\n",
            "Epoch 46: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.2665 - accuracy: 0.9177 - val_loss: 0.2064 - val_accuracy: 0.9298\n",
            "Epoch 47/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.2771 - accuracy: 0.9114\n",
            "Epoch 47: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.2775 - accuracy: 0.9109 - val_loss: 0.2038 - val_accuracy: 0.9350\n",
            "Epoch 48/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.2575 - accuracy: 0.9096\n",
            "Epoch 48: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.2606 - accuracy: 0.9096 - val_loss: 0.2003 - val_accuracy: 0.9343\n",
            "Epoch 49/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2590 - accuracy: 0.9123\n",
            "Epoch 49: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.2588 - accuracy: 0.9124 - val_loss: 0.1902 - val_accuracy: 0.9449\n",
            "Epoch 50/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2637 - accuracy: 0.9151\n",
            "Epoch 50: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.2635 - accuracy: 0.9152 - val_loss: 0.1857 - val_accuracy: 0.9502\n",
            "Epoch 51/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.2442 - accuracy: 0.9230\n",
            "Epoch 51: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.2443 - accuracy: 0.9215 - val_loss: 0.1767 - val_accuracy: 0.9517\n",
            "Epoch 52/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.2567 - accuracy: 0.9130\n",
            "Epoch 52: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.2547 - accuracy: 0.9134 - val_loss: 0.1722 - val_accuracy: 0.9569\n",
            "Epoch 53/1000\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.2391 - accuracy: 0.9195\n",
            "Epoch 53: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.2389 - accuracy: 0.9207 - val_loss: 0.1696 - val_accuracy: 0.9524\n",
            "Epoch 54/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9267\n",
            "Epoch 54: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.2326 - accuracy: 0.9267 - val_loss: 0.1741 - val_accuracy: 0.9509\n",
            "Epoch 55/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.2329 - accuracy: 0.9299\n",
            "Epoch 55: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2335 - accuracy: 0.9295 - val_loss: 0.1702 - val_accuracy: 0.9532\n",
            "Epoch 56/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.2378 - accuracy: 0.9210\n",
            "Epoch 56: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.2384 - accuracy: 0.9212 - val_loss: 0.1684 - val_accuracy: 0.9517\n",
            "Epoch 57/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2291 - accuracy: 0.9277\n",
            "Epoch 57: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 0.2289 - accuracy: 0.9277 - val_loss: 0.1633 - val_accuracy: 0.9585\n",
            "Epoch 58/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.2214 - accuracy: 0.9312\n",
            "Epoch 58: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.2200 - accuracy: 0.9315 - val_loss: 0.1574 - val_accuracy: 0.9585\n",
            "Epoch 59/1000\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.2066 - accuracy: 0.9354\n",
            "Epoch 59: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.2151 - accuracy: 0.9318 - val_loss: 0.1537 - val_accuracy: 0.9577\n",
            "Epoch 60/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.2195 - accuracy: 0.9320\n",
            "Epoch 60: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.2239 - accuracy: 0.9298 - val_loss: 0.1559 - val_accuracy: 0.9592\n",
            "Epoch 61/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.2273 - accuracy: 0.9307\n",
            "Epoch 61: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.2266 - accuracy: 0.9315 - val_loss: 0.1513 - val_accuracy: 0.9592\n",
            "Epoch 62/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.2131 - accuracy: 0.9355\n",
            "Epoch 62: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.2131 - accuracy: 0.9355 - val_loss: 0.1591 - val_accuracy: 0.9554\n",
            "Epoch 63/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9320\n",
            "Epoch 63: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2139 - accuracy: 0.9320 - val_loss: 0.1427 - val_accuracy: 0.9668\n",
            "Epoch 64/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.9194\n",
            "Epoch 64: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.2479 - accuracy: 0.9194 - val_loss: 0.1394 - val_accuracy: 0.9653\n",
            "Epoch 65/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.2136 - accuracy: 0.9351\n",
            "Epoch 65: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.2124 - accuracy: 0.9358 - val_loss: 0.1372 - val_accuracy: 0.9653\n",
            "Epoch 66/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.2046 - accuracy: 0.9375\n",
            "Epoch 66: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2034 - accuracy: 0.9378 - val_loss: 0.1361 - val_accuracy: 0.9637\n",
            "Epoch 67/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1992 - accuracy: 0.9405\n",
            "Epoch 67: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.1998 - accuracy: 0.9403 - val_loss: 0.1400 - val_accuracy: 0.9645\n",
            "Epoch 68/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9400\n",
            "Epoch 68: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1954 - accuracy: 0.9401 - val_loss: 0.1295 - val_accuracy: 0.9705\n",
            "Epoch 69/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1959 - accuracy: 0.9401\n",
            "Epoch 69: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.1959 - accuracy: 0.9401 - val_loss: 0.1334 - val_accuracy: 0.9645\n",
            "Epoch 70/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1962 - accuracy: 0.9410\n",
            "Epoch 70: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.1964 - accuracy: 0.9408 - val_loss: 0.1303 - val_accuracy: 0.9690\n",
            "Epoch 71/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.9335\n",
            "Epoch 71: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.2065 - accuracy: 0.9335 - val_loss: 0.1272 - val_accuracy: 0.9683\n",
            "Epoch 72/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1760 - accuracy: 0.9488\n",
            "Epoch 72: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1754 - accuracy: 0.9494 - val_loss: 0.1331 - val_accuracy: 0.9637\n",
            "Epoch 73/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1859 - accuracy: 0.9440\n",
            "Epoch 73: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 0.1850 - accuracy: 0.9436 - val_loss: 0.1270 - val_accuracy: 0.9683\n",
            "Epoch 74/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1943 - accuracy: 0.9422\n",
            "Epoch 74: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.1927 - accuracy: 0.9428 - val_loss: 0.1229 - val_accuracy: 0.9713\n",
            "Epoch 75/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1850 - accuracy: 0.9424\n",
            "Epoch 75: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1843 - accuracy: 0.9428 - val_loss: 0.1248 - val_accuracy: 0.9705\n",
            "Epoch 76/1000\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.1825 - accuracy: 0.9459\n",
            "Epoch 76: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1804 - accuracy: 0.9461 - val_loss: 0.1282 - val_accuracy: 0.9713\n",
            "Epoch 77/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1760 - accuracy: 0.9473\n",
            "Epoch 77: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1776 - accuracy: 0.9469 - val_loss: 0.1299 - val_accuracy: 0.9713\n",
            "Epoch 78/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1764 - accuracy: 0.9438\n",
            "Epoch 78: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.1762 - accuracy: 0.9439 - val_loss: 0.1213 - val_accuracy: 0.9736\n",
            "Epoch 79/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1683 - accuracy: 0.9470\n",
            "Epoch 79: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1672 - accuracy: 0.9481 - val_loss: 0.1231 - val_accuracy: 0.9683\n",
            "Epoch 80/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9451\n",
            "Epoch 80: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 0.1781 - accuracy: 0.9451 - val_loss: 0.1312 - val_accuracy: 0.9683\n",
            "Epoch 81/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1685 - accuracy: 0.9476\n",
            "Epoch 81: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.1684 - accuracy: 0.9476 - val_loss: 0.1244 - val_accuracy: 0.9698\n",
            "Epoch 82/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1710 - accuracy: 0.9478\n",
            "Epoch 82: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1708 - accuracy: 0.9479 - val_loss: 0.1216 - val_accuracy: 0.9705\n",
            "Epoch 83/1000\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.1615 - accuracy: 0.9513\n",
            "Epoch 83: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1630 - accuracy: 0.9522 - val_loss: 0.1179 - val_accuracy: 0.9728\n",
            "Epoch 84/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9488\n",
            "Epoch 84: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.1716 - accuracy: 0.9486 - val_loss: 0.1125 - val_accuracy: 0.9728\n",
            "Epoch 85/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1665 - accuracy: 0.9531\n",
            "Epoch 85: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1695 - accuracy: 0.9524 - val_loss: 0.1148 - val_accuracy: 0.9736\n",
            "Epoch 86/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1734 - accuracy: 0.9464\n",
            "Epoch 86: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 15ms/step - loss: 0.1708 - accuracy: 0.9474 - val_loss: 0.1140 - val_accuracy: 0.9736\n",
            "Epoch 87/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1590 - accuracy: 0.9551\n",
            "Epoch 87: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1588 - accuracy: 0.9552 - val_loss: 0.1201 - val_accuracy: 0.9721\n",
            "Epoch 88/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1628 - accuracy: 0.9515\n",
            "Epoch 88: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1592 - accuracy: 0.9524 - val_loss: 0.1142 - val_accuracy: 0.9743\n",
            "Epoch 89/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1668 - accuracy: 0.9503\n",
            "Epoch 89: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.1656 - accuracy: 0.9507 - val_loss: 0.1193 - val_accuracy: 0.9705\n",
            "Epoch 90/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9481\n",
            "Epoch 90: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1742 - accuracy: 0.9481 - val_loss: 0.1195 - val_accuracy: 0.9690\n",
            "Epoch 91/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1655 - accuracy: 0.9488\n",
            "Epoch 91: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1656 - accuracy: 0.9479 - val_loss: 0.1202 - val_accuracy: 0.9698\n",
            "Epoch 92/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1591 - accuracy: 0.9536\n",
            "Epoch 92: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1590 - accuracy: 0.9537 - val_loss: 0.1105 - val_accuracy: 0.9698\n",
            "Epoch 93/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1675 - accuracy: 0.9492\n",
            "Epoch 93: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1695 - accuracy: 0.9471 - val_loss: 0.1161 - val_accuracy: 0.9698\n",
            "Epoch 94/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1571 - accuracy: 0.9572\n",
            "Epoch 94: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1570 - accuracy: 0.9572 - val_loss: 0.1175 - val_accuracy: 0.9705\n",
            "Epoch 95/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1660 - accuracy: 0.9488\n",
            "Epoch 95: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1661 - accuracy: 0.9489 - val_loss: 0.1087 - val_accuracy: 0.9728\n",
            "Epoch 96/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9486\n",
            "Epoch 96: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1591 - accuracy: 0.9486 - val_loss: 0.1162 - val_accuracy: 0.9690\n",
            "Epoch 97/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.2241 - accuracy: 0.9344\n",
            "Epoch 97: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.2262 - accuracy: 0.9343 - val_loss: 0.1299 - val_accuracy: 0.9645\n",
            "Epoch 98/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1586 - accuracy: 0.9544\n",
            "Epoch 98: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 0.1603 - accuracy: 0.9537 - val_loss: 0.1131 - val_accuracy: 0.9721\n",
            "Epoch 99/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1582 - accuracy: 0.9495\n",
            "Epoch 99: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 0.1600 - accuracy: 0.9486 - val_loss: 0.1097 - val_accuracy: 0.9751\n",
            "Epoch 100/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1554 - accuracy: 0.9526\n",
            "Epoch 100: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1569 - accuracy: 0.9524 - val_loss: 0.1125 - val_accuracy: 0.9698\n",
            "Epoch 101/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1609 - accuracy: 0.9539\n",
            "Epoch 101: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1592 - accuracy: 0.9547 - val_loss: 0.1081 - val_accuracy: 0.9736\n",
            "Epoch 102/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1555 - accuracy: 0.9520\n",
            "Epoch 102: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1598 - accuracy: 0.9499 - val_loss: 0.1069 - val_accuracy: 0.9736\n",
            "Epoch 103/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9512\n",
            "Epoch 103: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1517 - accuracy: 0.9512 - val_loss: 0.1054 - val_accuracy: 0.9758\n",
            "Epoch 104/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1513 - accuracy: 0.9566\n",
            "Epoch 104: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1533 - accuracy: 0.9542 - val_loss: 0.1085 - val_accuracy: 0.9713\n",
            "Epoch 105/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9396\n",
            "Epoch 105: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.1933 - accuracy: 0.9396 - val_loss: 0.1066 - val_accuracy: 0.9758\n",
            "Epoch 106/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.9564\n",
            "Epoch 106: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1503 - accuracy: 0.9564 - val_loss: 0.1061 - val_accuracy: 0.9721\n",
            "Epoch 107/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.9595\n",
            "Epoch 107: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 0.1427 - accuracy: 0.9595 - val_loss: 0.1083 - val_accuracy: 0.9713\n",
            "Epoch 108/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1443 - accuracy: 0.9546\n",
            "Epoch 108: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1443 - accuracy: 0.9547 - val_loss: 0.1070 - val_accuracy: 0.9758\n",
            "Epoch 109/1000\n",
            "24/32 [=====================>........] - ETA: 0s - loss: 0.1348 - accuracy: 0.9596\n",
            "Epoch 109: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1489 - accuracy: 0.9552 - val_loss: 0.1032 - val_accuracy: 0.9736\n",
            "Epoch 110/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9572\n",
            "Epoch 110: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.1433 - accuracy: 0.9572 - val_loss: 0.1155 - val_accuracy: 0.9675\n",
            "Epoch 111/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9551\n",
            "Epoch 111: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 0.1499 - accuracy: 0.9552 - val_loss: 0.1038 - val_accuracy: 0.9721\n",
            "Epoch 112/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1409 - accuracy: 0.9577\n",
            "Epoch 112: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1427 - accuracy: 0.9562 - val_loss: 0.1175 - val_accuracy: 0.9705\n",
            "Epoch 113/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.2031 - accuracy: 0.9378\n",
            "Epoch 113: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2029 - accuracy: 0.9378 - val_loss: 0.1140 - val_accuracy: 0.9743\n",
            "Epoch 114/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1440 - accuracy: 0.9542\n",
            "Epoch 114: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.1448 - accuracy: 0.9537 - val_loss: 0.1047 - val_accuracy: 0.9736\n",
            "Epoch 115/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1441 - accuracy: 0.9586\n",
            "Epoch 115: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1456 - accuracy: 0.9585 - val_loss: 0.1043 - val_accuracy: 0.9736\n",
            "Epoch 116/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.9580\n",
            "Epoch 116: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1361 - accuracy: 0.9580 - val_loss: 0.1046 - val_accuracy: 0.9743\n",
            "Epoch 117/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 0.9589\n",
            "Epoch 117: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1440 - accuracy: 0.9590 - val_loss: 0.1007 - val_accuracy: 0.9751\n",
            "Epoch 118/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1544 - accuracy: 0.9526\n",
            "Epoch 118: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1543 - accuracy: 0.9527 - val_loss: 0.1053 - val_accuracy: 0.9728\n",
            "Epoch 119/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1317 - accuracy: 0.9598\n",
            "Epoch 119: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.1379 - accuracy: 0.9577 - val_loss: 0.1014 - val_accuracy: 0.9713\n",
            "Epoch 120/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9587\n",
            "Epoch 120: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1388 - accuracy: 0.9585 - val_loss: 0.1045 - val_accuracy: 0.9728\n",
            "Epoch 121/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1481 - accuracy: 0.9544\n",
            "Epoch 121: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1456 - accuracy: 0.9549 - val_loss: 0.1013 - val_accuracy: 0.9743\n",
            "Epoch 122/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1380 - accuracy: 0.9553\n",
            "Epoch 122: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1420 - accuracy: 0.9549 - val_loss: 0.1031 - val_accuracy: 0.9728\n",
            "Epoch 123/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.9572\n",
            "Epoch 123: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1337 - accuracy: 0.9572 - val_loss: 0.1052 - val_accuracy: 0.9728\n",
            "Epoch 124/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.9582\n",
            "Epoch 124: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 0.1361 - accuracy: 0.9582 - val_loss: 0.1024 - val_accuracy: 0.9736\n",
            "Epoch 125/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1276 - accuracy: 0.9618\n",
            "Epoch 125: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1292 - accuracy: 0.9620 - val_loss: 0.1014 - val_accuracy: 0.9728\n",
            "Epoch 126/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1354 - accuracy: 0.9576\n",
            "Epoch 126: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1303 - accuracy: 0.9595 - val_loss: 0.0982 - val_accuracy: 0.9751\n",
            "Epoch 127/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1398 - accuracy: 0.9565\n",
            "Epoch 127: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1366 - accuracy: 0.9582 - val_loss: 0.1059 - val_accuracy: 0.9728\n",
            "Epoch 128/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.9580\n",
            "Epoch 128: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1417 - accuracy: 0.9580 - val_loss: 0.1056 - val_accuracy: 0.9698\n",
            "Epoch 129/1000\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.1238 - accuracy: 0.9612\n",
            "Epoch 129: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1306 - accuracy: 0.9580 - val_loss: 0.1028 - val_accuracy: 0.9736\n",
            "Epoch 130/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.9582\n",
            "Epoch 130: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1352 - accuracy: 0.9582 - val_loss: 0.0998 - val_accuracy: 0.9751\n",
            "Epoch 131/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1262 - accuracy: 0.9615\n",
            "Epoch 131: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1273 - accuracy: 0.9620 - val_loss: 0.1074 - val_accuracy: 0.9713\n",
            "Epoch 132/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1399 - accuracy: 0.9585\n",
            "Epoch 132: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1390 - accuracy: 0.9590 - val_loss: 0.1026 - val_accuracy: 0.9736\n",
            "Epoch 133/1000\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.1426 - accuracy: 0.9588\n",
            "Epoch 133: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1439 - accuracy: 0.9577 - val_loss: 0.1001 - val_accuracy: 0.9736\n",
            "Epoch 134/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1456 - accuracy: 0.9596\n",
            "Epoch 134: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1447 - accuracy: 0.9600 - val_loss: 0.0998 - val_accuracy: 0.9758\n",
            "Epoch 135/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1352 - accuracy: 0.9574\n",
            "Epoch 135: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1351 - accuracy: 0.9575 - val_loss: 0.1077 - val_accuracy: 0.9713\n",
            "Epoch 136/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1321 - accuracy: 0.9592\n",
            "Epoch 136: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1311 - accuracy: 0.9595 - val_loss: 0.0980 - val_accuracy: 0.9728\n",
            "Epoch 137/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1197 - accuracy: 0.9637\n",
            "Epoch 137: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1209 - accuracy: 0.9640 - val_loss: 0.1019 - val_accuracy: 0.9751\n",
            "Epoch 138/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1182 - accuracy: 0.9693\n",
            "Epoch 138: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1181 - accuracy: 0.9693 - val_loss: 0.0980 - val_accuracy: 0.9736\n",
            "Epoch 139/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1309 - accuracy: 0.9597\n",
            "Epoch 139: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1308 - accuracy: 0.9597 - val_loss: 0.0996 - val_accuracy: 0.9728\n",
            "Epoch 140/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1330 - accuracy: 0.9573\n",
            "Epoch 140: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1302 - accuracy: 0.9575 - val_loss: 0.0995 - val_accuracy: 0.9713\n",
            "Epoch 141/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1214 - accuracy: 0.9612\n",
            "Epoch 141: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1235 - accuracy: 0.9602 - val_loss: 0.0960 - val_accuracy: 0.9751\n",
            "Epoch 142/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 0.9642\n",
            "Epoch 142: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1195 - accuracy: 0.9642 - val_loss: 0.1014 - val_accuracy: 0.9721\n",
            "Epoch 143/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.9615\n",
            "Epoch 143: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.1255 - accuracy: 0.9615 - val_loss: 0.0994 - val_accuracy: 0.9736\n",
            "Epoch 144/1000\n",
            "28/32 [=========================>....] - ETA: 0s - loss: 0.1330 - accuracy: 0.9607\n",
            "Epoch 144: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1316 - accuracy: 0.9607 - val_loss: 0.0984 - val_accuracy: 0.9736\n",
            "Epoch 145/1000\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.1268 - accuracy: 0.9616\n",
            "Epoch 145: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1244 - accuracy: 0.9627 - val_loss: 0.0958 - val_accuracy: 0.9751\n",
            "Epoch 146/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1242 - accuracy: 0.9631\n",
            "Epoch 146: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1209 - accuracy: 0.9640 - val_loss: 0.0969 - val_accuracy: 0.9728\n",
            "Epoch 147/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1212 - accuracy: 0.9606\n",
            "Epoch 147: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1177 - accuracy: 0.9622 - val_loss: 0.0950 - val_accuracy: 0.9789\n",
            "Epoch 148/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1224 - accuracy: 0.9644\n",
            "Epoch 148: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1214 - accuracy: 0.9650 - val_loss: 0.0947 - val_accuracy: 0.9751\n",
            "Epoch 149/1000\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.1333 - accuracy: 0.9588\n",
            "Epoch 149: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1265 - accuracy: 0.9605 - val_loss: 0.0938 - val_accuracy: 0.9781\n",
            "Epoch 150/1000\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.1374 - accuracy: 0.9579\n",
            "Epoch 150: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1348 - accuracy: 0.9605 - val_loss: 0.0990 - val_accuracy: 0.9736\n",
            "Epoch 151/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1329 - accuracy: 0.9583\n",
            "Epoch 151: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1324 - accuracy: 0.9597 - val_loss: 0.0969 - val_accuracy: 0.9751\n",
            "Epoch 152/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1285 - accuracy: 0.9601\n",
            "Epoch 152: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1252 - accuracy: 0.9610 - val_loss: 0.1001 - val_accuracy: 0.9728\n",
            "Epoch 153/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9615\n",
            "Epoch 153: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1259 - accuracy: 0.9615 - val_loss: 0.0984 - val_accuracy: 0.9728\n",
            "Epoch 154/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1171 - accuracy: 0.9655\n",
            "Epoch 154: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1171 - accuracy: 0.9655 - val_loss: 0.0968 - val_accuracy: 0.9743\n",
            "Epoch 155/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.9622\n",
            "Epoch 155: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1331 - accuracy: 0.9622 - val_loss: 0.0991 - val_accuracy: 0.9713\n",
            "Epoch 156/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1317 - accuracy: 0.9573\n",
            "Epoch 156: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1310 - accuracy: 0.9580 - val_loss: 0.0952 - val_accuracy: 0.9766\n",
            "Epoch 157/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1154 - accuracy: 0.9639\n",
            "Epoch 157: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1154 - accuracy: 0.9640 - val_loss: 0.0939 - val_accuracy: 0.9766\n",
            "Epoch 158/1000\n",
            "26/32 [=======================>......] - ETA: 0s - loss: 0.1183 - accuracy: 0.9657\n",
            "Epoch 158: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1199 - accuracy: 0.9650 - val_loss: 0.0946 - val_accuracy: 0.9758\n",
            "Epoch 159/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1173 - accuracy: 0.9631\n",
            "Epoch 159: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1145 - accuracy: 0.9645 - val_loss: 0.1009 - val_accuracy: 0.9758\n",
            "Epoch 160/1000\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.1147 - accuracy: 0.9616\n",
            "Epoch 160: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1200 - accuracy: 0.9612 - val_loss: 0.0991 - val_accuracy: 0.9766\n",
            "Epoch 161/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9675\n",
            "Epoch 161: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1140 - accuracy: 0.9675 - val_loss: 0.0988 - val_accuracy: 0.9751\n",
            "Epoch 162/1000\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9640\n",
            "Epoch 162: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1159 - accuracy: 0.9640 - val_loss: 0.0974 - val_accuracy: 0.9766\n",
            "Epoch 163/1000\n",
            "27/32 [========================>.....] - ETA: 0s - loss: 0.1218 - accuracy: 0.9598\n",
            "Epoch 163: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1209 - accuracy: 0.9607 - val_loss: 0.0959 - val_accuracy: 0.9743\n",
            "Epoch 164/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9627\n",
            "Epoch 164: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.1138 - accuracy: 0.9627 - val_loss: 0.0977 - val_accuracy: 0.9743\n",
            "Epoch 165/1000\n",
            "31/32 [============================>.] - ETA: 0s - loss: 0.1198 - accuracy: 0.9624\n",
            "Epoch 165: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1197 - accuracy: 0.9625 - val_loss: 0.0948 - val_accuracy: 0.9758\n",
            "Epoch 166/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1221 - accuracy: 0.9623\n",
            "Epoch 166: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.1225 - accuracy: 0.9622 - val_loss: 0.0979 - val_accuracy: 0.9743\n",
            "Epoch 167/1000\n",
            "29/32 [==========================>...] - ETA: 0s - loss: 0.1184 - accuracy: 0.9647\n",
            "Epoch 167: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.1194 - accuracy: 0.9637 - val_loss: 0.0991 - val_accuracy: 0.9758\n",
            "Epoch 168/1000\n",
            "25/32 [======================>.......] - ETA: 0s - loss: 0.1093 - accuracy: 0.9675\n",
            "Epoch 168: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1175 - accuracy: 0.9632 - val_loss: 0.0939 - val_accuracy: 0.9736\n",
            "Epoch 169/1000\n",
            "30/32 [===========================>..] - ETA: 0s - loss: 0.1222 - accuracy: 0.9633\n",
            "Epoch 169: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1195 - accuracy: 0.9642 - val_loss: 0.0969 - val_accuracy: 0.9751\n",
            "Epoch 169: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78ca3414b6d0>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "UndgdmVrvIf0"
      },
      "outputs": [],
      "source": [
        "# 保存したモデルのロード\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-mNsRi9vIf0",
        "outputId": "f5746001-b70b-437b-adb5-29082c1bd715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 236ms/step\n",
            "[9.6649086e-01 1.6121580e-03 7.5118884e-04 3.1145761e-02]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# 推論テスト\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1crca9AvIf1"
      },
      "source": [
        "# 混同行列"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2_-4Z6gxdjr"
      },
      "source": [
        "## 1. 非LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "5jZ_v27IvIf1",
        "outputId": "b58c0015-bddb-4064-9bd2-023f681c3ec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       395\n",
            "           1       0.99      0.98      0.98       295\n",
            "           2       0.96      0.98      0.97       307\n",
            "           3       0.96      0.94      0.95       327\n",
            "\n",
            "    accuracy                           0.98      1324\n",
            "   macro avg       0.97      0.97      0.97      1324\n",
            "weighted avg       0.98      0.98      0.98      1324\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ri2DWcZxiK_"
      },
      "source": [
        "## 2. LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "6QMeLAWXxOn6",
        "outputId": "264bde3b-a727-4f7e-8719-110ca953627a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42/42 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       395\n",
            "           1       0.99      0.98      0.98       295\n",
            "           2       0.96      0.98      0.97       307\n",
            "           3       0.96      0.94      0.95       327\n",
            "\n",
            "    accuracy                           0.98      1324\n",
            "   macro avg       0.97      0.97      0.97      1324\n",
            "weighted avg       0.98      0.98      0.98      1324\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJuzeaNvvIf1"
      },
      "source": [
        "# Tensorflow-Lite用のモデルへ変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-69qqNEvIf1",
        "outputId": "a3ecf5f2-9701-4135-c74f-8dbb49b90f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "# 推論専用のモデルとして保存\n",
        "model.save(model_save_path, include_optimizer=False)\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lmuf-AvHvIf1"
      },
      "outputs": [],
      "source": [
        "tflite_save_path = 'model/point_history_classifier/point_history_classifier.tflite'\n",
        "saved_model_path = 'saved_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng1Cd-x_15Rb",
        "outputId": "b047557f-cfee-4e71-8c10-59abfae0978d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(model, saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhyT5-_rvIf1",
        "outputId": "81509bbf-717a-4bc7-fcae-172dae78d19a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-26 12:20:50.136795: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
            "2025-12-26 12:20:50.136828: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
            "2025-12-26 12:20:50.136963: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: saved_model\n",
            "2025-12-26 12:20:50.144549: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
            "2025-12-26 12:20:50.144610: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: saved_model\n",
            "2025-12-26 12:20:50.173791: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
            "2025-12-26 12:20:50.225091: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: saved_model\n",
            "2025-12-26 12:20:50.263513: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 126552 microseconds.\n",
            "2025-12-26 12:20:50.442763: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1918] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
            "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
            "Details:\n",
            "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x16xf32>>>) : {device = \"\"}\n",
            "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x16xf32>>>, tensor<i32>, tensor<?x16xf32>) -> (tensor<!tf_type.variant<tensor<?x16xf32>>>) : {device = \"\"}\n",
            "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x16xf32>>>, tensor<2xi32>) -> (tensor<?x?x16xf32>) : {device = \"\", num_elements = -1 : i64}\n",
            "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "15104"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# モデルを変換\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA9TzY4cUEAX"
      },
      "source": [
        "# ONNXへの変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NXFcvxDUCUK",
        "outputId": "359e8933-fc40-4f49-c958-489116e6ac24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-26 12:22:31.764574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-12-26 12:22:31.837266: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-26 12:22:31.840474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2025-12-26 12:22:31.840486: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2025-12-26 12:22:31.855556: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
            "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
            "  File \"/usr/local/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
            "    __import__(pkg_name)\n",
            "  File \"/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/tf2onnx/__init__.py\", line 10, in <module>\n",
            "    from . import verbose_logging as logging\n",
            "  File \"/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/tf2onnx/verbose_logging.py\", line 14, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/tensorflow/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/tensorflow/python/eager/context.py\", line 29, in <module>\n",
            "    from tensorflow.core.framework import function_pb2\n",
            "  File \"/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py\", line 16, in <module>\n",
            "    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n",
            "  File \"/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py\", line 16, in <module>\n",
            "    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\n",
            "  File \"/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py\", line 16, in <module>\n",
            "    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n",
            "  File \"/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py\", line 16, in <module>\n",
            "    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
            "  File \"/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\", line 36, in <module>\n",
            "    _descriptor.FieldDescriptor(\n",
            "  File \"/home/mat/Documents/iot/hand-gesture-recognition-mediapipe/.env/lib/python3.10/site-packages/google/protobuf/descriptor.py\", line 675, in __new__\n",
            "    _message.Message._CheckCalledFromGeneratedFile()\n",
            "TypeError: Descriptors cannot be created directly.\n",
            "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
            "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
            " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
            " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
            "\n",
            "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n"
          ]
        }
      ],
      "source": [
        "!python -m tf2onnx.convert --opset 11 --saved-model saved_model --output point_history_classifier.onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!onnxsim point_history_classifier.onnx point_history_classifier.onnx\n",
        "!onnxsim point_history_classifier.onnx point_history_classifier.onnx\n",
        "!onnxsim point_history_classifier.onnx point_history_classifier.onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5Jl26OLvIf2"
      },
      "source": [
        "# 推論テスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ne_SRyCMvIf2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
            "INFO: TfLiteFlexDelegate delegate: 2 nodes delegated out of 17 nodes with 2 partitions.\n",
            "\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3c_WoJQYvIf2",
        "outputId": "b890a4f3-976b-4e9a-9c92-d482d686ae42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'serving_default_input_1:0', 'index': 0, 'shape': array([ 1, 32], dtype=int32), 'shape_signature': array([-1, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ],
      "source": [
        "# 入出力テンソルを取得\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(input_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mUe7K3p4vIf2"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qaTIiDI9vIf2",
        "outputId": "e040f0a9-266f-42fe-8274-c6c90195eac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2.29 ms, sys: 0 ns, total: 2.29 ms\n",
            "Wall time: 1.15 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# 推論実施\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PcIXAVVPvIf2",
        "outputId": "97889009-e95a-420c-ccfc-fa8112543d06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9.7926694e-01 1.3084083e-03 1.1282025e-04 1.9311896e-02]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
